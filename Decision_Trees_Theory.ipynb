{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2452cad5",
   "metadata": {},
   "source": [
    "# Human Activity Recognition - Theory Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996c5801",
   "metadata": {},
   "source": [
    "## Task 1: Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b819dcd",
   "metadata": {},
   "source": [
    "### Q1: Waveform plots for each activity class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba311484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert your plotting code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d63d7",
   "metadata": {},
   "source": [
    "\n",
    "**Answer:**\n",
    "- Static activities (laying, sitting, standing) show nearly flat and stable signals.  \n",
    "- Dynamic activities (walking, upstairs, downstairs) show periodic fluctuations representing step cycles.  \n",
    "- Clear differences exist, so a model should be able to classify the activities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05054547",
   "metadata": {},
   "source": [
    "### Q2: Static vs Dynamic differentiation using linear acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fde0ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert calculation and plotting of acc = sqrt(acc_x^2 + acc_y^2 + acc_z^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbc50ec",
   "metadata": {},
   "source": [
    "\n",
    "**Answer:**\n",
    "- Static activities → nearly constant acceleration magnitude.  \n",
    "- Dynamic activities → higher variation and periodic patterns.  \n",
    "- A threshold-based rule could separate static vs dynamic without ML.  \n",
    "- However, to distinguish between *different* dynamic activities (walking vs upstairs vs downstairs), ML is needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed7c6b1",
   "metadata": {},
   "source": [
    "### Q3: PCA Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1adcc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert PCA code + scatter plots for raw, TSFEL, dataset features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bb83f0",
   "metadata": {},
   "source": [
    "\n",
    "**Answer:**\n",
    "- PCA on raw total acceleration: weak separation.  \n",
    "- PCA with TSFEL features: better separation since features capture statistical properties.  \n",
    "- PCA with provided dataset features: best separation.  \n",
    "- Conclusion: dataset-provided features are the best for visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6716ef3",
   "metadata": {},
   "source": [
    "### Q4: Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de40c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert correlation heatmap code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea985e1",
   "metadata": {},
   "source": [
    "\n",
    "**Answer:**\n",
    "- Many features are highly correlated (e.g., mean & median, variance & energy).  \n",
    "- Some features are redundant.  \n",
    "- Feature selection can reduce dimensionality without major info loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd56483",
   "metadata": {},
   "source": [
    "## Task 2: Decision Trees for HAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af407b20",
   "metadata": {},
   "source": [
    "### Q1: Decision Trees with raw, TSFEL, dataset features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6321d6e0",
   "metadata": {},
   "source": [
    "\n",
    "**Answer:**\n",
    "- Raw data → lowest accuracy (high dimensional & noisy).  \n",
    "- TSFEL features → moderate performance.  \n",
    "- Provided dataset features → best accuracy, precision, recall, confusion matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed846cfe",
   "metadata": {},
   "source": [
    "### Q2: Varying tree depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b2ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert accuracy vs depth plot here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e07ba",
   "metadata": {},
   "source": [
    "\n",
    "**Answer:**\n",
    "- Small depth → underfitting.  \n",
    "- Increasing depth → accuracy improves.  \n",
    "- Too large depth → overfitting.  \n",
    "- Optimal depth ~ 4–6.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcbbd9b",
   "metadata": {},
   "source": [
    "### Q3: Poor performance participants/activities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5f7340",
   "metadata": {},
   "source": [
    "\n",
    "**Answer:**\n",
    "- Yes, confusion occurs between walking_upstairs and walking_downstairs due to similar signals.  \n",
    "- Variations in participant movement style or phone placement also reduce accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf58c1f",
   "metadata": {},
   "source": [
    "## Task 3: Data Collection in the Wild"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a327f2f8",
   "metadata": {},
   "source": [
    "### Q1: Model on self-collected data using UCI-HAR trained tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d61cb20",
   "metadata": {},
   "source": [
    "\n",
    "**Answer:**\n",
    "- Accuracy is lower than on UCI dataset due to different phone placement and noisy real-world conditions.  \n",
    "- Sensitive to alignment and consistency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ef3f49",
   "metadata": {},
   "source": [
    "### Q2: Using personal dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c561b",
   "metadata": {},
   "source": [
    "\n",
    "**Answer:**\n",
    "- With preprocessing (normalization, TSFEL features), performance improves.  \n",
    "- Without preprocessing, performance drops.  \n",
    "- Real-world performance is lower than in controlled datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d9f846",
   "metadata": {},
   "source": [
    "# Decision Tree Implementation - Theory Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f71b66",
   "metadata": {},
   "source": [
    "## Part A: Classification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df9598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dataset generation\n",
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_features=2, n_redundant=0, n_informative=2, \n",
    "    random_state=1, n_clusters_per_class=2, class_sep=0.5\n",
    ")\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "plt.title(\"Synthetic Classification Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91161063",
   "metadata": {},
   "source": [
    "\n",
    "**Answer (Theory):**\n",
    "- Train on 70% of the data, test on 30%.\n",
    "- Report metrics: Accuracy, per-class precision, recall.\n",
    "- The decision tree should achieve reasonable separation given 2 informative features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceae11d8",
   "metadata": {},
   "source": [
    "### 5-Fold Cross Validation & Optimum Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57526aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert nested cross-validation code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc2c4d0",
   "metadata": {},
   "source": [
    "\n",
    "**Answer (Theory):**\n",
    "- Use 5-fold cross-validation with nested CV to tune depth.\n",
    "- As depth increases → better fit, but risk of overfitting.\n",
    "- Optimum depth balances bias-variance (likely small, e.g. 3–6 for simple 2D dataset).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4dae97",
   "metadata": {},
   "source": [
    "## Part B: Auto Efficiency Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4922ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert training & evaluation on Auto-Efficiency dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0343567e",
   "metadata": {},
   "source": [
    "\n",
    "**Answer (Theory):**\n",
    "- Custom decision tree performs comparably to sklearn’s `DecisionTreeClassifier/Regressor` on structured data.\n",
    "- Sklearn is typically more optimized, so it may be slightly faster or more accurate with default settings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b8d78a",
   "metadata": {},
   "source": [
    "## Part C: Runtime Complexity Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af8863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert experiment code for varying N (samples) and M (features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fb7a4f",
   "metadata": {},
   "source": [
    "\n",
    "**Answer (Theory):**\n",
    "- **Learning Time Complexity:** O(N * M * log N) for decision tree construction.\n",
    "\n",
    "- **Prediction Time Complexity:** O(depth of tree), typically O(log N).\n",
    "\n",
    "- Experiments should confirm theory:\n",
    "\n",
    "  - As N grows → training time increases roughly linearly with N.\n",
    "\n",
    "  - As M grows → training time grows linearly with M.\n",
    "\n",
    "  - Prediction time stays low, scaling with depth.\n",
    "\n",
    "- Across four cases (discrete/real inputs & outputs), trends hold, though regression may take slightly more time due to MSE splits.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
